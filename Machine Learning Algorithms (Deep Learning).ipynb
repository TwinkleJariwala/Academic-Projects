{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwZAW-FHHp1o"
      },
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsJORlHTHp1s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from astropy.table import QTable, Table, Column\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBq69G5Hp1u"
      },
      "source": [
        "# Data Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "rRcIHw2DHp1u",
        "outputId": "7e3ee1d8-c607-4551-a0d9-ecc1fdfb4ddf"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68a1d083-4fa2-4b08-bec7-479fdd3b857d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68a1d083-4fa2-4b08-bec7-479fdd3b857d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2021 HW2data.csv to 2021 HW2data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "MSB8e1q3XQRc",
        "outputId": "673dd6a7-300c-4f3d-e6ae-ee1e20183bb1"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['2021 HW2data.csv']),header= None)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.3630</td>\n",
              "      <td>2.0779</td>\n",
              "      <td>2.0059</td>\n",
              "      <td>1.8738</td>\n",
              "      <td>2.4091</td>\n",
              "      <td>2.7567</td>\n",
              "      <td>3.06160</td>\n",
              "      <td>3.2438</td>\n",
              "      <td>3.5714</td>\n",
              "      <td>3.4489</td>\n",
              "      <td>3.4149</td>\n",
              "      <td>3.0607</td>\n",
              "      <td>3.3529</td>\n",
              "      <td>3.4739</td>\n",
              "      <td>3.6257</td>\n",
              "      <td>3.7866</td>\n",
              "      <td>4.1557</td>\n",
              "      <td>4.0827</td>\n",
              "      <td>4.0132</td>\n",
              "      <td>3.6466</td>\n",
              "      <td>3.0099</td>\n",
              "      <td>2.4859</td>\n",
              "      <td>2.0213</td>\n",
              "      <td>1.4998</td>\n",
              "      <td>1.2414</td>\n",
              "      <td>1.1377</td>\n",
              "      <td>1.0624</td>\n",
              "      <td>1.3115</td>\n",
              "      <td>1.7967</td>\n",
              "      <td>2.1816</td>\n",
              "      <td>2.7634</td>\n",
              "      <td>3.4696</td>\n",
              "      <td>4.2004</td>\n",
              "      <td>4.7987</td>\n",
              "      <td>5.0522</td>\n",
              "      <td>4.7985</td>\n",
              "      <td>4.3834</td>\n",
              "      <td>4.0134</td>\n",
              "      <td>3.4752</td>\n",
              "      <td>2.9479</td>\n",
              "      <td>...</td>\n",
              "      <td>5.3061</td>\n",
              "      <td>4.6004</td>\n",
              "      <td>3.9951</td>\n",
              "      <td>3.3981</td>\n",
              "      <td>2.7250</td>\n",
              "      <td>2.6336</td>\n",
              "      <td>2.7379</td>\n",
              "      <td>2.4321</td>\n",
              "      <td>2.0255</td>\n",
              "      <td>1.8441</td>\n",
              "      <td>1.7177</td>\n",
              "      <td>1.7344</td>\n",
              "      <td>1.8481</td>\n",
              "      <td>1.8572</td>\n",
              "      <td>1.9347</td>\n",
              "      <td>1.9470</td>\n",
              "      <td>1.8401</td>\n",
              "      <td>1.6534</td>\n",
              "      <td>1.6553</td>\n",
              "      <td>1.5893</td>\n",
              "      <td>1.4814</td>\n",
              "      <td>1.3621</td>\n",
              "      <td>1.58450</td>\n",
              "      <td>2.04950</td>\n",
              "      <td>2.58400</td>\n",
              "      <td>2.8410</td>\n",
              "      <td>3.2619</td>\n",
              "      <td>3.4649</td>\n",
              "      <td>3.1260</td>\n",
              "      <td>2.7496</td>\n",
              "      <td>2.4973</td>\n",
              "      <td>2.7431</td>\n",
              "      <td>3.0460</td>\n",
              "      <td>3.5700</td>\n",
              "      <td>4.0879</td>\n",
              "      <td>4.7550</td>\n",
              "      <td>4.5093</td>\n",
              "      <td>4.0592</td>\n",
              "      <td>3.6183</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.3351</td>\n",
              "      <td>3.8362</td>\n",
              "      <td>3.9755</td>\n",
              "      <td>4.3974</td>\n",
              "      <td>4.3581</td>\n",
              "      <td>4.8556</td>\n",
              "      <td>4.33880</td>\n",
              "      <td>4.2298</td>\n",
              "      <td>3.9837</td>\n",
              "      <td>3.8393</td>\n",
              "      <td>3.2790</td>\n",
              "      <td>2.7431</td>\n",
              "      <td>2.1119</td>\n",
              "      <td>1.7562</td>\n",
              "      <td>1.6227</td>\n",
              "      <td>1.6901</td>\n",
              "      <td>1.6920</td>\n",
              "      <td>1.8352</td>\n",
              "      <td>2.0380</td>\n",
              "      <td>2.1356</td>\n",
              "      <td>2.6559</td>\n",
              "      <td>3.5131</td>\n",
              "      <td>4.4236</td>\n",
              "      <td>5.1298</td>\n",
              "      <td>5.6037</td>\n",
              "      <td>5.3061</td>\n",
              "      <td>4.6004</td>\n",
              "      <td>3.9951</td>\n",
              "      <td>3.3981</td>\n",
              "      <td>2.7250</td>\n",
              "      <td>2.6336</td>\n",
              "      <td>2.7379</td>\n",
              "      <td>2.4321</td>\n",
              "      <td>2.0255</td>\n",
              "      <td>1.8441</td>\n",
              "      <td>1.7177</td>\n",
              "      <td>1.7344</td>\n",
              "      <td>1.8481</td>\n",
              "      <td>1.8572</td>\n",
              "      <td>1.9347</td>\n",
              "      <td>...</td>\n",
              "      <td>1.7264</td>\n",
              "      <td>1.5377</td>\n",
              "      <td>1.6122</td>\n",
              "      <td>1.8658</td>\n",
              "      <td>1.8218</td>\n",
              "      <td>1.6876</td>\n",
              "      <td>1.7552</td>\n",
              "      <td>1.7617</td>\n",
              "      <td>1.7515</td>\n",
              "      <td>1.8736</td>\n",
              "      <td>1.9472</td>\n",
              "      <td>1.8389</td>\n",
              "      <td>1.7975</td>\n",
              "      <td>1.9404</td>\n",
              "      <td>2.3188</td>\n",
              "      <td>3.0621</td>\n",
              "      <td>3.3923</td>\n",
              "      <td>3.3859</td>\n",
              "      <td>3.7074</td>\n",
              "      <td>3.7011</td>\n",
              "      <td>3.3150</td>\n",
              "      <td>3.4839</td>\n",
              "      <td>3.97570</td>\n",
              "      <td>4.02850</td>\n",
              "      <td>4.18510</td>\n",
              "      <td>4.3807</td>\n",
              "      <td>4.0930</td>\n",
              "      <td>3.5671</td>\n",
              "      <td>2.9868</td>\n",
              "      <td>2.3359</td>\n",
              "      <td>1.6718</td>\n",
              "      <td>1.4243</td>\n",
              "      <td>1.5971</td>\n",
              "      <td>1.6985</td>\n",
              "      <td>1.8106</td>\n",
              "      <td>1.9223</td>\n",
              "      <td>1.9805</td>\n",
              "      <td>1.9841</td>\n",
              "      <td>2.2742</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.9888</td>\n",
              "      <td>2.2007</td>\n",
              "      <td>1.5232</td>\n",
              "      <td>1.2309</td>\n",
              "      <td>1.1879</td>\n",
              "      <td>1.0139</td>\n",
              "      <td>0.82491</td>\n",
              "      <td>1.3230</td>\n",
              "      <td>2.0033</td>\n",
              "      <td>2.6067</td>\n",
              "      <td>3.4173</td>\n",
              "      <td>4.3156</td>\n",
              "      <td>4.6136</td>\n",
              "      <td>4.4431</td>\n",
              "      <td>4.2084</td>\n",
              "      <td>4.1017</td>\n",
              "      <td>4.1192</td>\n",
              "      <td>4.0010</td>\n",
              "      <td>3.6551</td>\n",
              "      <td>3.3508</td>\n",
              "      <td>3.0509</td>\n",
              "      <td>2.6722</td>\n",
              "      <td>2.2802</td>\n",
              "      <td>2.0488</td>\n",
              "      <td>1.8762</td>\n",
              "      <td>1.7264</td>\n",
              "      <td>1.5377</td>\n",
              "      <td>1.6122</td>\n",
              "      <td>1.8658</td>\n",
              "      <td>1.8218</td>\n",
              "      <td>1.6876</td>\n",
              "      <td>1.7552</td>\n",
              "      <td>1.7617</td>\n",
              "      <td>1.7515</td>\n",
              "      <td>1.8736</td>\n",
              "      <td>1.9472</td>\n",
              "      <td>1.8389</td>\n",
              "      <td>1.7975</td>\n",
              "      <td>1.9404</td>\n",
              "      <td>2.3188</td>\n",
              "      <td>...</td>\n",
              "      <td>1.6749</td>\n",
              "      <td>1.6750</td>\n",
              "      <td>1.9850</td>\n",
              "      <td>2.3529</td>\n",
              "      <td>2.7056</td>\n",
              "      <td>3.1522</td>\n",
              "      <td>3.4378</td>\n",
              "      <td>3.4077</td>\n",
              "      <td>3.5126</td>\n",
              "      <td>3.3150</td>\n",
              "      <td>3.1979</td>\n",
              "      <td>3.2256</td>\n",
              "      <td>3.4095</td>\n",
              "      <td>3.4915</td>\n",
              "      <td>3.8555</td>\n",
              "      <td>3.7350</td>\n",
              "      <td>3.4905</td>\n",
              "      <td>3.1630</td>\n",
              "      <td>2.7132</td>\n",
              "      <td>2.0700</td>\n",
              "      <td>1.6002</td>\n",
              "      <td>1.2203</td>\n",
              "      <td>0.92127</td>\n",
              "      <td>0.78088</td>\n",
              "      <td>0.90382</td>\n",
              "      <td>1.3752</td>\n",
              "      <td>2.0166</td>\n",
              "      <td>2.6460</td>\n",
              "      <td>3.1065</td>\n",
              "      <td>3.6137</td>\n",
              "      <td>3.8819</td>\n",
              "      <td>3.9583</td>\n",
              "      <td>3.9145</td>\n",
              "      <td>4.1136</td>\n",
              "      <td>4.3393</td>\n",
              "      <td>3.9726</td>\n",
              "      <td>3.5225</td>\n",
              "      <td>3.6245</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.7536</td>\n",
              "      <td>3.4015</td>\n",
              "      <td>4.0295</td>\n",
              "      <td>4.4294</td>\n",
              "      <td>4.5497</td>\n",
              "      <td>4.4177</td>\n",
              "      <td>4.09180</td>\n",
              "      <td>3.8896</td>\n",
              "      <td>3.6138</td>\n",
              "      <td>3.0180</td>\n",
              "      <td>2.6134</td>\n",
              "      <td>2.2989</td>\n",
              "      <td>1.7815</td>\n",
              "      <td>1.3916</td>\n",
              "      <td>1.5243</td>\n",
              "      <td>1.4783</td>\n",
              "      <td>1.5184</td>\n",
              "      <td>1.6710</td>\n",
              "      <td>1.4866</td>\n",
              "      <td>1.3976</td>\n",
              "      <td>1.6634</td>\n",
              "      <td>1.7063</td>\n",
              "      <td>1.5138</td>\n",
              "      <td>1.6874</td>\n",
              "      <td>1.7295</td>\n",
              "      <td>1.6749</td>\n",
              "      <td>1.6750</td>\n",
              "      <td>1.9850</td>\n",
              "      <td>2.3529</td>\n",
              "      <td>2.7056</td>\n",
              "      <td>3.1522</td>\n",
              "      <td>3.4378</td>\n",
              "      <td>3.4077</td>\n",
              "      <td>3.5126</td>\n",
              "      <td>3.3150</td>\n",
              "      <td>3.1979</td>\n",
              "      <td>3.2256</td>\n",
              "      <td>3.4095</td>\n",
              "      <td>3.4915</td>\n",
              "      <td>3.8555</td>\n",
              "      <td>...</td>\n",
              "      <td>3.9320</td>\n",
              "      <td>4.4306</td>\n",
              "      <td>4.7756</td>\n",
              "      <td>5.0455</td>\n",
              "      <td>4.6569</td>\n",
              "      <td>4.3694</td>\n",
              "      <td>3.7538</td>\n",
              "      <td>2.8815</td>\n",
              "      <td>2.3253</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>1.7491</td>\n",
              "      <td>1.4590</td>\n",
              "      <td>1.6394</td>\n",
              "      <td>1.9035</td>\n",
              "      <td>2.5358</td>\n",
              "      <td>3.2687</td>\n",
              "      <td>4.1206</td>\n",
              "      <td>4.7709</td>\n",
              "      <td>5.0287</td>\n",
              "      <td>4.9990</td>\n",
              "      <td>5.0543</td>\n",
              "      <td>4.8308</td>\n",
              "      <td>4.48990</td>\n",
              "      <td>4.12130</td>\n",
              "      <td>3.63620</td>\n",
              "      <td>2.8954</td>\n",
              "      <td>2.4679</td>\n",
              "      <td>2.1420</td>\n",
              "      <td>1.9152</td>\n",
              "      <td>1.6305</td>\n",
              "      <td>1.6182</td>\n",
              "      <td>1.6513</td>\n",
              "      <td>1.4662</td>\n",
              "      <td>1.3964</td>\n",
              "      <td>1.3607</td>\n",
              "      <td>1.3314</td>\n",
              "      <td>1.2890</td>\n",
              "      <td>1.6128</td>\n",
              "      <td>1.7203</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.4033</td>\n",
              "      <td>2.2425</td>\n",
              "      <td>2.3487</td>\n",
              "      <td>1.9880</td>\n",
              "      <td>1.8548</td>\n",
              "      <td>1.9522</td>\n",
              "      <td>1.95860</td>\n",
              "      <td>1.8108</td>\n",
              "      <td>1.6193</td>\n",
              "      <td>1.4585</td>\n",
              "      <td>1.3875</td>\n",
              "      <td>1.2306</td>\n",
              "      <td>1.2359</td>\n",
              "      <td>1.4657</td>\n",
              "      <td>1.8516</td>\n",
              "      <td>1.9066</td>\n",
              "      <td>2.5636</td>\n",
              "      <td>3.3693</td>\n",
              "      <td>4.0764</td>\n",
              "      <td>4.2700</td>\n",
              "      <td>4.4251</td>\n",
              "      <td>4.1178</td>\n",
              "      <td>3.6478</td>\n",
              "      <td>3.2564</td>\n",
              "      <td>3.5896</td>\n",
              "      <td>3.9320</td>\n",
              "      <td>4.4306</td>\n",
              "      <td>4.7756</td>\n",
              "      <td>5.0455</td>\n",
              "      <td>4.6569</td>\n",
              "      <td>4.3694</td>\n",
              "      <td>3.7538</td>\n",
              "      <td>2.8815</td>\n",
              "      <td>2.3253</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>1.7491</td>\n",
              "      <td>1.4590</td>\n",
              "      <td>1.6394</td>\n",
              "      <td>1.9035</td>\n",
              "      <td>2.5358</td>\n",
              "      <td>...</td>\n",
              "      <td>3.3252</td>\n",
              "      <td>3.7527</td>\n",
              "      <td>4.0025</td>\n",
              "      <td>4.4005</td>\n",
              "      <td>5.3609</td>\n",
              "      <td>6.0200</td>\n",
              "      <td>5.6337</td>\n",
              "      <td>4.9674</td>\n",
              "      <td>4.1698</td>\n",
              "      <td>2.8144</td>\n",
              "      <td>1.9173</td>\n",
              "      <td>1.8026</td>\n",
              "      <td>1.8074</td>\n",
              "      <td>1.7450</td>\n",
              "      <td>1.9072</td>\n",
              "      <td>2.0633</td>\n",
              "      <td>2.1482</td>\n",
              "      <td>2.2176</td>\n",
              "      <td>2.1179</td>\n",
              "      <td>1.9391</td>\n",
              "      <td>2.0517</td>\n",
              "      <td>2.1875</td>\n",
              "      <td>2.29680</td>\n",
              "      <td>2.48630</td>\n",
              "      <td>2.70840</td>\n",
              "      <td>2.5567</td>\n",
              "      <td>2.5436</td>\n",
              "      <td>2.8319</td>\n",
              "      <td>3.7025</td>\n",
              "      <td>4.1852</td>\n",
              "      <td>4.2846</td>\n",
              "      <td>4.4212</td>\n",
              "      <td>4.4358</td>\n",
              "      <td>4.1614</td>\n",
              "      <td>4.3205</td>\n",
              "      <td>4.5931</td>\n",
              "      <td>4.9707</td>\n",
              "      <td>4.9617</td>\n",
              "      <td>4.3099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 129 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0       1       2       3       4    ...     124     125     126     127  128\n",
              "0  2.3630  2.0779  2.0059  1.8738  2.4091  ...  4.7550  4.5093  4.0592  3.6183    0\n",
              "1  3.3351  3.8362  3.9755  4.3974  4.3581  ...  1.9223  1.9805  1.9841  2.2742    0\n",
              "2  2.9888  2.2007  1.5232  1.2309  1.1879  ...  3.9726  3.5225  3.6245  3.1923    0\n",
              "3  2.7536  3.4015  4.0295  4.4294  4.5497  ...  1.3314  1.2890  1.6128  1.7203    0\n",
              "4  2.4033  2.2425  2.3487  1.9880  1.8548  ...  4.5931  4.9707  4.9617  4.3099    0\n",
              "\n",
              "[5 rows x 129 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea8WkmodHp1v"
      },
      "source": [
        "labels = df.iloc[:, -1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm80xjjXHp1w"
      },
      "source": [
        "data = df.drop(128,axis = 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhTMFr-lHp1x"
      },
      "source": [
        "Xtrain,Xtest,ytrain,ytest = train_test_split(data,labels,test_size = 0.2, shuffle = True )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jV9ioXLHp1x"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPd-tXCjHp1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad60c19-d5a2-47d8-8da2-1edd482818b8"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "y_nb = nb.fit(Xtrain, ytrain)\n",
        "y_hat_nb= y_nb.predict(Xtest)\n",
        "nb_mse=mean_squared_error(ytest,y_hat_nb)\n",
        "print(\"Naive Bayes MSE:\", nb_mse)\n",
        "a_nb = accuracy_score(ytest,y_hat_nb)\n",
        "print(\"Naive Bayes Accuracy:\",a_nb )\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes MSE: 2.365\n",
            "Naive Bayes Accuracy: 0.5695238095238095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxl4CzdcHp1y"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwbvSjoIHp1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abebc59-52b8-4634-fbfa-67c2d6ea0d42"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(solver='newton-cg',multi_class = 'auto')\n",
        "y_lr = LR.fit(Xtrain, ytrain)\n",
        "y_hat_lr= y_lr.predict(Xtest)\n",
        "lr_mse=mean_squared_error(ytest,y_hat_lr)\n",
        "print(\"Logistic Regression MSE:\", lr_mse)\n",
        "a_lr = accuracy_score(ytest,y_hat_lr)\n",
        "print(\"Logistic Regression Accuracy:\", a_lr )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression MSE: 2.6078571428571427\n",
            "Logistic Regression Accuracy: 0.5757142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKl6Qg8SHp10"
      },
      "source": [
        "# K nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXoX9GTTHp10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726c6d2e-769a-4275-ce45-1863ef12d06e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "y_knn = knn.fit(Xtrain, ytrain)\n",
        "y_hat_knn= y_knn.predict(Xtest)\n",
        "knn_mse= mean_squared_error(ytest,y_hat_knn)\n",
        "print(\"KNN MSE:\",knn_mse)\n",
        "a_knn = accuracy_score(ytest,y_hat_knn)\n",
        "print(\"KNN Accuracy:\", a_knn)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN MSE: 2.4435714285714285\n",
            "KNN Accuracy: 0.6540476190476191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nynqAthjHp11"
      },
      "source": [
        "# Decision Tree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_raotmtHp12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c167842f-8c28-4933-f9d9-a3a02b6693f0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=0)\n",
        "y_dt = dt.fit(Xtrain, ytrain)\n",
        "y_hat_dt= y_dt.predict(Xtest)\n",
        "dt_mse=mean_squared_error(ytest,y_hat_dt)\n",
        "print(\"Decision Tree MSE:\", dt_mse)\n",
        "a_dt = accuracy_score(ytest,y_hat_dt)\n",
        "print(\"Decision Tree Accuracy:\", a_dt)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 2.862857142857143\n",
            "Decision Tree Accuracy: 0.5852380952380952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XS0p7JLHp13"
      },
      "source": [
        "# Support Vector Machine "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AH_Y5GNvHp13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6db0c0-3303-47ef-9b01-7127bf6e9824"
      },
      "source": [
        "from sklearn import svm\n",
        "SVM = svm.NuSVC(gamma = 'auto',random_state=0)\n",
        "y_svm = SVM.fit(Xtrain, ytrain)\n",
        "y_hat_svm= y_svm.predict(Xtest)\n",
        "svm_mse=mean_squared_error(ytest,y_hat_svm)\n",
        "print(\"SVM MSE:\",svm_mse )\n",
        "a_svm = accuracy_score(ytest,y_hat_svm)\n",
        "print(\"SVM Accuracy:\", a_svm)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM MSE: 2.615952380952381\n",
            "SVM Accuracy: 0.5964285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LBBk5KhHp14"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxyk_NcFHp15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78b2dda-4ce7-480f-d2fe-f205c22b2212"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=9, random_state=0)\n",
        "y_hat_rf = rf.fit(Xtrain, ytrain).predict(Xtest)\n",
        "rf_mse=mean_squared_error(ytest,y_hat_rf)\n",
        "print(\"Random Forest MSE:\",rf_mse )\n",
        "a_rf = accuracy_score(ytest,y_hat_rf)\n",
        "print(\"Random Forest Accuracy:\", a_rf)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest MSE: 2.579285714285714\n",
            "Random Forest Accuracy: 0.6676190476190477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjtn-YqHp18"
      },
      "source": [
        "# Bonus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl7y677xHp18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3c91d6-47bb-4ca9-c515-fd318aae0246"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(n_estimators=250)\n",
        "y_hat_gb = gb.fit(Xtrain, ytrain).predict(Xtest)\n",
        "gb_mse= mean_squared_error(ytest,y_hat_gb)\n",
        "print(\"GBC MSE:\",gb_mse)\n",
        "a_gb = gb.score(Xtest,ytest)\n",
        "print(\"GBC Accuracy:\", a_gb)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBC MSE: 2.2252380952380952\n",
            "GBC Accuracy: 0.6766666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0ihhPzHp19"
      },
      "source": [
        " \n",
        "#Accuracy Table\n",
        "arr = [('Naive Bayes',nb_mse,a_nb),('Logistic Regression',lr_mse,a_lr),('K-Nearest Neighbor',knn_mse,a_knn),('Decision Tree',dt_mse,a_dt),('Support Vector Machine',svm_mse,a_svm),('Random Forest',rf_mse,a_rf),('Gradient Bossting Classifier',gb_mse,a_gb)]\n",
        "Accuracy_Table=Table(rows=arr, names=('Model', 'MSE', 'Accuracy')) \n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "zk3vL9jvXBsf",
        "outputId": "c4455062-10e4-4cf4-a114-9eab4c082bc5"
      },
      "source": [
        "Accuracy_Table"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div><i>Table length=7</i>\n",
              "<table id=\"table139945495690000\" class=\"table-striped table-bordered table-condensed\">\n",
              "<thead><tr><th>Model</th><th>MSE</th><th>Accuracy</th></tr></thead>\n",
              "<thead><tr><th>str28</th><th>float64</th><th>float64</th></tr></thead>\n",
              "<tr><td>Naive Bayes</td><td>2.365</td><td>0.5695238095238095</td></tr>\n",
              "<tr><td>Logistic Regression</td><td>2.6078571428571427</td><td>0.5757142857142857</td></tr>\n",
              "<tr><td>K-Nearest Neighbor</td><td>2.4435714285714285</td><td>0.6540476190476191</td></tr>\n",
              "<tr><td>Decision Tree</td><td>2.862857142857143</td><td>0.5852380952380952</td></tr>\n",
              "<tr><td>Support Vector Machine</td><td>2.615952380952381</td><td>0.5964285714285714</td></tr>\n",
              "<tr><td>Random Forest</td><td>2.579285714285714</td><td>0.6676190476190477</td></tr>\n",
              "<tr><td>Gradient Bossting Classifier</td><td>2.2252380952380952</td><td>0.6766666666666666</td></tr>\n",
              "</table></div>"
            ],
            "text/plain": [
              "<Table length=7>\n",
              "           Model                    MSE              Accuracy     \n",
              "           str28                  float64            float64      \n",
              "---------------------------- ------------------ ------------------\n",
              "                 Naive Bayes              2.365 0.5695238095238095\n",
              "         Logistic Regression 2.6078571428571427 0.5757142857142857\n",
              "          K-Nearest Neighbor 2.4435714285714285 0.6540476190476191\n",
              "               Decision Tree  2.862857142857143 0.5852380952380952\n",
              "      Support Vector Machine  2.615952380952381 0.5964285714285714\n",
              "               Random Forest  2.579285714285714 0.6676190476190477\n",
              "Gradient Bossting Classifier 2.2252380952380952 0.6766666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}